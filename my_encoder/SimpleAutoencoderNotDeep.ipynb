{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(30000,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(30000, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import skimage\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "img_folder = r'C:\\Users\\Kamil Ogrodowski\\Desktop\\Obrazowanie\\218447-medical_imaging-788b05f861ac\\dataset'\n",
    "img_width = 100\n",
    "img_height = 100\n",
    "\n",
    "# Read data\n",
    "data = pd.read_csv(r'C:\\Users\\Kamil Ogrodowski\\Desktop\\Obrazowanie\\218447-medical_imaging-788b05f861ac\\dataset\\GTruth.csv')\n",
    "\n",
    "# Split to train_data, val_data, test_data\n",
    "train_data, test_data = train_test_split(data)\n",
    "\n",
    "def read_img(fileid):\n",
    "    \"\"\"\n",
    "    Read and resize img, adjust channels. \n",
    "    Caution: This function is not independent, it uses global vars: img_folder, img_channels\n",
    "    @param file: file id, int\n",
    "    \"\"\"\n",
    "    img = skimage.io.imread(img_folder +'\\\\'+ str(fileid) + '.jpeg')\n",
    "    img = skimage.transform.resize(img, (img_width, img_height), mode='reflect')\n",
    "    # A few image are grey, duplicate them for to have 3 alpha channels.\n",
    "    if(len(img.shape) < 3):\n",
    "        img = np.dstack([img, img, img])\n",
    "    return img\n",
    "                        \n",
    "# Train data\n",
    "train_X = np.stack(train_data['Id'].apply(read_img))\n",
    "test_X = np.stack(test_data['Id'].apply(read_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4392, 30000)\n",
      "(1464, 30000)\n"
     ]
    }
   ],
   "source": [
    "train_X = train_X.astype('float32') / 255.\n",
    "test_X = test_X.astype('float32') / 255.\n",
    "train_X = train_X.reshape((len(train_X), np.prod(train_X.shape[1:])))\n",
    "test_X = test_X.reshape((len(test_X), np.prod(test_X.shape[1:])))\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4392 samples, validate on 1464 samples\n",
      "Epoch 1/50\n",
      "4392/4392 [==============================] - 12s 3ms/step - loss: 0.6932 - val_loss: 0.6932\n",
      "Epoch 2/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6931 - val_loss: 0.6929\n",
      "Epoch 3/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6928 - val_loss: 0.6927\n",
      "Epoch 4/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6927 - val_loss: 0.6926\n",
      "Epoch 5/50\n",
      "4392/4392 [==============================] - 11s 2ms/step - loss: 0.6926 - val_loss: 0.6925\n",
      "Epoch 6/50\n",
      "4392/4392 [==============================] - 11s 2ms/step - loss: 0.6923 - val_loss: 0.6922\n",
      "Epoch 7/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6921 - val_loss: 0.6921\n",
      "Epoch 8/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6920 - val_loss: 0.6919\n",
      "Epoch 9/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6918 - val_loss: 0.6916\n",
      "Epoch 10/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6916 - val_loss: 0.6915\n",
      "Epoch 11/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6915 - val_loss: 0.6914\n",
      "Epoch 12/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6914 - val_loss: 0.6914\n",
      "Epoch 13/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6914 - val_loss: 0.6913\n",
      "Epoch 14/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6913 - val_loss: 0.6912\n",
      "Epoch 15/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6912 - val_loss: 0.6910\n",
      "Epoch 16/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6909 - val_loss: 0.6908\n",
      "Epoch 17/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6908 - val_loss: 0.6907\n",
      "Epoch 18/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6906 - val_loss: 0.6905\n",
      "Epoch 19/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6904 - val_loss: 0.6903\n",
      "Epoch 20/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6902 - val_loss: 0.6901\n",
      "Epoch 21/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6901 - val_loss: 0.6900\n",
      "Epoch 22/50\n",
      "4392/4392 [==============================] - 11s 2ms/step - loss: 0.6899 - val_loss: 0.6897\n",
      "Epoch 23/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6897 - val_loss: 0.6896\n",
      "Epoch 24/50\n",
      "4392/4392 [==============================] - 11s 2ms/step - loss: 0.6895 - val_loss: 0.6895\n",
      "Epoch 25/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6895 - val_loss: 0.6894\n",
      "Epoch 26/50\n",
      "4392/4392 [==============================] - 11s 2ms/step - loss: 0.6894 - val_loss: 0.6894\n",
      "Epoch 27/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6893 - val_loss: 0.6893\n",
      "Epoch 28/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6892 - val_loss: 0.6891\n",
      "Epoch 29/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6890 - val_loss: 0.6889\n",
      "Epoch 30/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6888 - val_loss: 0.6887\n",
      "Epoch 31/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6887 - val_loss: 0.6886\n",
      "Epoch 32/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6885 - val_loss: 0.6884\n",
      "Epoch 33/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6883 - val_loss: 0.6882\n",
      "Epoch 34/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6881 - val_loss: 0.6880\n",
      "Epoch 35/50\n",
      "4392/4392 [==============================] - 10s 2ms/step - loss: 0.6880 - val_loss: 0.6879\n",
      "Epoch 36/50\n",
      "4392/4392 [==============================] - 11s 2ms/step - loss: 0.6878 - val_loss: 0.6877\n",
      "Epoch 37/50\n",
      "4392/4392 [==============================] - 12s 3ms/step - loss: 0.6877 - val_loss: 0.6876\n",
      "Epoch 38/50\n",
      "4392/4392 [==============================] - 13s 3ms/step - loss: 0.6876 - val_loss: 0.6875\n",
      "Epoch 39/50\n",
      "4392/4392 [==============================] - 11s 3ms/step - loss: 0.6875 - val_loss: 0.6874\n",
      "Epoch 40/50\n",
      "4392/4392 [==============================] - 11s 3ms/step - loss: 0.6873 - val_loss: 0.6873\n",
      "Epoch 41/50\n",
      "4392/4392 [==============================] - 11s 3ms/step - loss: 0.6872 - val_loss: 0.6871\n",
      "Epoch 42/50\n",
      "4392/4392 [==============================] - 11s 3ms/step - loss: 0.6870 - val_loss: 0.6870\n",
      "Epoch 43/50\n",
      "4392/4392 [==============================] - 11s 3ms/step - loss: 0.6869 - val_loss: 0.6868\n",
      "Epoch 44/50\n",
      "4392/4392 [==============================] - 11s 3ms/step - loss: 0.6867 - val_loss: 0.6866\n",
      "Epoch 45/50\n",
      "4392/4392 [==============================] - 11s 3ms/step - loss: 0.6865 - val_loss: 0.6864\n",
      "Epoch 46/50\n",
      "4392/4392 [==============================] - 11s 3ms/step - loss: 0.6864 - val_loss: 0.6863\n",
      "Epoch 47/50\n",
      "4392/4392 [==============================] - 11s 3ms/step - loss: 0.6862 - val_loss: 0.6861\n",
      "Epoch 48/50\n",
      "4392/4392 [==============================] - 11s 2ms/step - loss: 0.6861 - val_loss: 0.6860\n",
      "Epoch 49/50\n",
      "4392/4392 [==============================] - 11s 3ms/step - loss: 0.6859 - val_loss: 0.6858\n",
      "Epoch 50/50\n",
      "4352/4392 [============================>.] - ETA: 0s - loss: 0.6858"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(train_X, train_X,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_X, test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "# print(decoder)\n",
    "# print(vars(decoder))\n",
    "# print(dir(decoder))\n",
    "print(decoder.inputs[0].shape)\n",
    "encoded_imgs = encoder.predict(test_X)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imsave\n",
    "\n",
    "# n = 1  # how many digits we will display\n",
    "# plt.figure(figsize=(20, 4))\n",
    "# for i in range(n):\n",
    "#     # display original\n",
    "#     print(test_X[i])\n",
    "#     ax = plt.subplot(2, n, i + 1)\n",
    "#     plt.imshow(test_X[i].reshape(100, 100, 3))\n",
    "#     plt.gray()\n",
    "#     ax.get_xaxis().set_visible(False)\n",
    "#     ax.get_yaxis().set_visible(False)\n",
    "\n",
    "#     # display reconstruction\n",
    "#     ax = plt.subplot(2, n, i + 1 + n)\n",
    "#     plt.imshow(decoded_imgs[i].reshape(100, 100, 3))\n",
    "#     plt.gray()\n",
    "#     ax.get_xaxis().set_visible(False)\n",
    "#     ax.get_yaxis().set_visible(False)\n",
    "# plt.show()\n",
    "\n",
    "imsave('original.png', test_X[0].reshape(100, 100, 3))\n",
    "imsave('decoded.png', decoded_imgs[0].reshape(100, 100, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
